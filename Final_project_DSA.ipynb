{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eabd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import music\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from decision_tree import DecisionTreeClassifier\n",
    "from decision_tree import Node\n",
    "from \n",
    "\n",
    "def main(): \n",
    "    data= music.get_music()\n",
    "    art_key=list(data[0]['artist'].keys())\n",
    "    art_key[1]='artist_hotttnesss'   #rename the header since we have two hottness\n",
    "    art_key[2]='artist_id'\n",
    "    art_key[6]='artist_name'\n",
    "    song_key=list(data[0]['song'].keys())\n",
    "    song_key[8]='song_hotttnesss'\n",
    "    song_key[9]='song_id'\n",
    "    rel_key=list(data[0]['release'].keys())\n",
    "    rel_key[0]='release_id'\n",
    "    rel_key[1]='release_name'\n",
    "    headers=art_key+rel_key+song_key\n",
    "    all_row=[]\n",
    "    for i in range(len(data)):\n",
    "        art_val=list(data[i]['artist'].values())\n",
    "        rel_val=list(data[i]['release'].values())\n",
    "        song_val=list(data[i]['song'].values())\n",
    "        each_row=art_val+rel_val+song_val\n",
    "        all_row.append(each_row)\n",
    "    \n",
    "    filename = 'song.csv'\n",
    "    with open(filename, 'w', newline=\"\") as file:\n",
    "        csvwriter = csv.writer(file) \n",
    "        csvwriter.writerow(headers)\n",
    "        csvwriter.writerows(all_row)\n",
    "    \n",
    "    file_path = 'song.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(df)\n",
    "\n",
    "    #remove zero-number column\n",
    "\n",
    "    columns_to_remove = ['location', 'similar', 'mode','title','latitude','longitude','artist_id','release_id','release_name','song_id','year']\n",
    "\n",
    "    # Removing multiple columns\n",
    "    df = df.drop(columns=columns_to_remove, axis=1)\n",
    "\n",
    "    # Display the DataFrame after removing columns\n",
    "    print(df)\n",
    "\n",
    "    text_columns = []  # List to store columns with text data\n",
    "\n",
    "    # Iterate through columns and check data types\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == object:  # Check if the data type is 'object' (usually represents text)\n",
    "            text_columns.append(column)  # Add the column name to the list\n",
    "            print(column)\n",
    "    \n",
    "    #mapping terms and artist_name to a unique machine readable value and throw the old string column\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['terms_encode'] = label_encoder.fit_transform(df['terms'])\n",
    "    df['artist_name_encode'] = label_encoder.fit_transform(df['artist_name'])\n",
    "    columns_to_remove=['terms','artist_name']\n",
    "    df = df.drop(columns=columns_to_remove, axis=1)\n",
    "    print(df)\n",
    "\n",
    "    first_row = df.head(1)\n",
    "    first_row\n",
    "    text_columns = []  # List to store columns with text data\n",
    "\n",
    "    # Iterate through columns and check data types\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == object:  # Check if the data type is 'object' (usually represents text)\n",
    "            text_columns.append(column)  # Add the column name to the list\n",
    "            print(column)\n",
    "    \n",
    "    augmented_df = pd.concat([df] * 10, ignore_index=True)  # Duplicate DataFrame ten times\n",
    "    noise = np.random.normal(0.05, 0.02, size=(len(augmented_df), len(augmented_df.columns)))  # Generate Gaussian noise \n",
    "    augmented_df = augmented_df + noise  # Add noise to the DataFrame\n",
    "\n",
    "    augmented_df['familiarity_label'] = augmented_df['familiarity'].apply(lambda x: 1 if x > 0.5 else 0) # add labeled column and name it as familarity_label\n",
    "    columns_to_remove=['familiarity']\n",
    "    augmented_df = augmented_df.drop(columns=columns_to_remove, axis=1)\n",
    "    print(augmented_df)\n",
    "\n",
    "    X = augmented_df.drop(['familiarity_label'], axis=1)\n",
    "    Y = augmented_df['familiarity_label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d4a79a",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19098fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Split the data into training and testing sets\n",
    "    X = augmented_df.iloc[:500,:-1].values\n",
    "    Y = augmented_df.iloc[:500,-1].values.reshape(-1,1)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=6)\n",
    "    classifier.fit(X_train,Y_train)\n",
    "    classifier.print_tree()\n",
    "    # print(X_train)\n",
    "\n",
    "    # # Initialize the Decision Tree Classifier\n",
    "    # clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # # Fit the classifier on the training data\n",
    "    # clf.fit(X_train, y_train)\n",
    "\n",
    "    # # Make predictions on the test set\n",
    "    # y_pred = clf.predict(X_test)\n",
    "\n",
    "    # # Evaluate the classifier\n",
    "    # accuracy = accuracy_score(y_test, y_pred)\n",
    "    # conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    # class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4080d3",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b04ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter\n",
    "model = random_forest(X_train, y_train, n_estimators=100, max_features=3, max_depth=10, min_samples_split=2)\n",
    "preds = predict_rf(model, X_test)\n",
    "acc = sum(preds == y_test) / len(y_test)\n",
    "print(\"Testing accuracy: {}\".format(np.round(acc,3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
