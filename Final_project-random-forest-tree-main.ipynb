{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ca7876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import music\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from reformattedDecisionTree import DecisionTreeClassifier\n",
    "from reformattedDecisionTree import Node\n",
    "import RandomForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061117f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import GPUtil\n",
    "#GPUtil.getAvailable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eabd73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "data= music.get_music()\n",
    "art_key=list(data[0]['artist'].keys())\n",
    "art_key[1]='artist_hotttnesss'   #rename some of the header which has same name\n",
    "art_key[2]='artist_id'\n",
    "art_key[6]='artist_name'\n",
    "song_key=list(data[0]['song'].keys())\n",
    "song_key[8]='song_hotttnesss'\n",
    "song_key[9]='song_id'\n",
    "rel_key=list(data[0]['release'].keys())\n",
    "rel_key[0]='release_id'\n",
    "rel_key[1]='release_name'\n",
    "headers=art_key+rel_key+song_key\n",
    "all_row=[]\n",
    "for i in range(len(data)):\n",
    "    art_val=list(data[i]['artist'].values())\n",
    "    rel_val=list(data[i]['release'].values())\n",
    "    song_val=list(data[i]['song'].values())\n",
    "    each_row=art_val+rel_val+song_val\n",
    "    all_row.append(each_row)\n",
    "    \n",
    "filename = 'song.csv'\n",
    "with open(filename, 'w', newline=\"\") as file:\n",
    "    csvwriter = csv.writer(file) \n",
    "    csvwriter.writerow(headers)\n",
    "    csvwriter.writerows(all_row)\n",
    "    \n",
    "file_path = 'song.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b3db60",
   "metadata": {},
   "outputs": [],
   "source": [
    " #remove zero-number column\n",
    "\n",
    "columns_to_remove = ['location', 'similar', 'mode','title','latitude','longitude','artist_id','release_id','release_name','song_id','year']\n",
    "\n",
    "    # Removing multiple columns\n",
    "df = df.drop(columns=columns_to_remove, axis=1)\n",
    "\n",
    "    # Display the DataFrame after removing columns\n",
    "print(df)\n",
    "\n",
    "text_columns = []  # List to store columns with text data\n",
    "\n",
    "    # Iterate through columns and check data types\n",
    "for column in df.columns:\n",
    "        if df[column].dtype == object:  # Check if the data type is 'object' (usually represents text)\n",
    "            text_columns.append(column)  # Add the column name to the list\n",
    "            #print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cc3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #mapping terms and artist_name to a unique machine readable value and throw the old string column\n",
    "label_encoder = LabelEncoder()\n",
    "df['terms_encode'] = label_encoder.fit_transform(df['terms'])\n",
    "df['artist_name_encode'] = label_encoder.fit_transform(df['artist_name'])\n",
    "columns_to_remove=['terms','artist_name']\n",
    "df = df.drop(columns=columns_to_remove, axis=1)\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1281d1c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "augmented_df = pd.concat([df] * 10, ignore_index=True)  # Duplicate DataFrame ten times\n",
    "noise = np.random.normal(0.05, 0.02, size=(len(augmented_df), len(augmented_df.columns)))  # Generate Gaussian noise \n",
    "augmented_df = augmented_df + noise  # Add noise to the DataFrame\n",
    "\n",
    "augmented_df['familiarity_label'] = augmented_df['familiarity'].apply(lambda x: 1 if x > 0.6 else 0) # add labeled column and name it as familarity_label\n",
    "columns_to_remove=['familiarity']\n",
    "augmented_df = augmented_df.drop(columns=columns_to_remove, axis=1)\n",
    "print(augmented_df)\n",
    "\n",
    "X = augmented_df.drop(['familiarity_label'], axis=1)\n",
    "Y = augmented_df['familiarity_label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ce073b",
   "metadata": {},
   "source": [
    "## Random-forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18256682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up-to-date.\n",
      "libomp  is already installed but outdated (so it will be upgraded).\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libomp/manifests/17.0.6\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibomp\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libomp/blobs/sha256:1a771c79450\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libomp--17.0.6.arm64_monterey.bottle.tar.gz\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mCaveats\u001b[0m\n",
      "libomp is keg-only, which means it was not symlinked into /opt/homebrew,\n",
      "because it can override GCC headers and result in broken builds.\n",
      "\n",
      "For compilers to find libomp you may need to set:\n",
      "  export LDFLAGS=\"-L/opt/homebrew/opt/libomp/lib\"\n",
      "  export CPPFLAGS=\"-I/opt/homebrew/opt/libomp/include\"\n",
      "\u001b[34m==>\u001b[0m \u001b[1mSummary\u001b[0m\n",
      "🍺  /opt/homebrew/Cellar/libomp/17.0.6: 7 files, 1.7MB\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRunning `brew cleanup libomp`...\u001b[0m\n",
      "Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.\n",
      "Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n",
      "Removing: /opt/homebrew/Cellar/libomp/16.0.0... (7 files, 1.7MB)\n",
      "\u001b[32m==>\u001b[0m \u001b[1m`brew cleanup` has not been run in the last 30 days, running now...\u001b[0m\n",
      "Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.\n",
      "Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n",
      "Removing: /Users/zhiyuwang/Library/Caches/Homebrew/autoconf--2.71... (944.1KB)\n",
      "Removing: /Users/zhiyuwang/Library/Caches/Homebrew/automake--1.16.5... (970.5KB)\n",
      "Removing: /Users/zhiyuwang/Library/Caches/Homebrew/m4--1.4.19... (256.0KB)\n",
      "Removing: /Users/zhiyuwang/Library/Caches/Homebrew/m4_bottle_manifest--1.4.19... (8.7KB)\n",
      "Removing: /Users/zhiyuwang/Library/Caches/Homebrew/automake_bottle_manifest--1.16.5... (12.2KB)\n",
      "Removing: /Users/zhiyuwang/Library/Caches/Homebrew/autoconf_bottle_manifest--2.71... (11.7KB)\n",
      "Removing: /Users/zhiyuwang/Library/Logs/Homebrew/autoconf... (64B)\n",
      "Removing: /Users/zhiyuwang/Library/Logs/Homebrew/m4... (64B)\n",
      "Removing: /Users/zhiyuwang/Library/Logs/Homebrew/automake... (64B)\n"
     ]
    }
   ],
   "source": [
    "!brew update\n",
    "!arch -arm64 brew install  libomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f50197b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#parameter\n",
    "features= augmented_df.iloc[:500, :-1]\n",
    "target= augmented_df.iloc[:500, -1]\n",
    "X_train, x_test, Y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "print(Y_train.shape)\n",
    "model = RandomForest.random_forest(X_train, Y_train, n_estimators=100, max_features=3, max_depth=10, min_samples_split=2)\n",
    "preds = predict_rf(model, X_test)\n",
    "acc = sum(preds == y_test) / len(y_test)\n",
    "print(\"Testing accuracy: {}\".format(np.round(acc,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e23cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, pre)\n",
    "\n",
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='coolwarm')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b417eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22facf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m X_train, x_test, Y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(features, target, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(Y_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mRandomForest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_forest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_samples_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m preds \u001b[38;5;241m=\u001b[39m predict_rf(model, X_test)\n",
      "File \u001b[0;32m~/Desktop/DSA_final/DSA_final_project/RandomForest.py:132\u001b[0m, in \u001b[0;36mrandom_forest\u001b[0;34m(X_train, y_train, n_estimators, max_features, max_depth, min_samples_split)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_estimators):\n\u001b[1;32m    131\u001b[0m     X_bootstrap, y_bootstrap, X_oob, y_oob \u001b[38;5;241m=\u001b[39m draw_bootstrap(X_train, y_train)\n\u001b[0;32m--> 132\u001b[0m     tree \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_bootstrap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_bootstrap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_samples_split\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     tree_ls\u001b[38;5;241m.\u001b[39mappend(tree)\n\u001b[1;32m    134\u001b[0m     oob_error \u001b[38;5;241m=\u001b[39m oob_score(tree, X_oob, y_oob)\n",
      "File \u001b[0;32m~/Desktop/DSA_final/DSA_final_project/RandomForest.py:123\u001b[0m, in \u001b[0;36mbuild_tree\u001b[0;34m(X_bootstrap, y_bootstrap, max_depth, min_samples_split, max_features)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_tree\u001b[39m(X_bootstrap, y_bootstrap, max_depth, min_samples_split, max_features):\n\u001b[0;32m--> 123\u001b[0m     root_node \u001b[38;5;241m=\u001b[39m \u001b[43mfind_split_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_bootstrap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_bootstrap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     split_node(root_node, max_features, min_samples_split, max_depth, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m root_node\n",
      "File \u001b[0;32m~/Desktop/DSA_final/DSA_final_project/RandomForest.py:43\u001b[0m, in \u001b[0;36mfind_split_point\u001b[0;34m(X_bootstrap, y_bootstrap, max_features)\u001b[0m\n\u001b[1;32m     40\u001b[0m num_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_bootstrap[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(feature_ls) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_features:\n\u001b[0;32m---> 43\u001b[0m     feature_idx \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_idx \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m feature_ls:\n\u001b[1;32m     45\u001b[0m     feature_ls\u001b[38;5;241m.\u001b[39mextend(feature_idx)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/random.py:466\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    464\u001b[0m selected_add \u001b[38;5;241m=\u001b[39m selected\u001b[38;5;241m.\u001b[39madd\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k):\n\u001b[0;32m--> 466\u001b[0m     j \u001b[38;5;241m=\u001b[39m \u001b[43mrandbelow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m selected:\n\u001b[1;32m    468\u001b[0m         j \u001b[38;5;241m=\u001b[39m randbelow(n)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/random.py:237\u001b[0m, in \u001b[0;36mRandom._randbelow_with_getrandbits\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow_without_getrandbits\n\u001b[1;32m    235\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_randbelow_with_getrandbits\u001b[39m(\u001b[38;5;28mself\u001b[39m, n):\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn a random int in the range [0,n).  Returns 0 if n==0.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#parameter\n",
    "features= augmented_df.iloc[:100, :-1]\n",
    "target= augmented_df.iloc[:100, -1]\n",
    "X_train, x_test, Y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "print(Y_train.shape)\n",
    "model = RandomForest.random_forest(X_train, Y_train, n_estimators=100, max_features=3, max_depth=10, min_samples_split=2)\n",
    "preds = predict_rf(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db9ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load sample data (replace this with your own data)\n",
    "data = load_iris()\n",
    "X = augmented_df.iloc[:500, :-1]\n",
    "y = augmented_df.iloc[:500, -1]\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Using LazyClassifier with Random Forest\n",
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Print the models and their performance\n",
    "print(models)\n",
    "\n",
    "# Example of getting the confusion matrix for Random Forest\n",
    "rf_predictions = predictions['RandomForestClassifier']\n",
    "conf_matrix = confusion_matrix(y_test, rf_predictions)\n",
    "\n",
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix - Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea72e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
